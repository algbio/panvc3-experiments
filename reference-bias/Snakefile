# Copyright (c) Tuukka Norri 2023
# Licenced under the MIT licence.

# vim: syntax=snakefile

REFERENCE_FA					= "../reference/hs37d5.fa"
TRUTH							= "../known-variants/HG001_GRCh37_1_22_v4.2.1_benchmark.vcf"
KNOWN_VARIANTS_PREFIX			= "../known-variants/ALL.chr"
KNOWN_VARIANTS_SUFFIX			= ".phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz"
SAMPLE_ID						= "HG001"
CHROMOSOMES						= ['1']
ALL_CHROMOSOMES					= ['1'] # For generating equivalent seeds when changing CHROMOSOMES
KNOWN_VARIANTS_REMOVED_SAMPLES	= ["NA12878"]
CONFIDENT_REGIONS				= "../known-variants/HG001_GRCh37_1_22_v4.2.1_benchmark.bed"

MEM_GB							= 168

READS_1							= f"reads/{SAMPLE_ID}.p1.fq.gz"
READS_2							= f"reads/{SAMPLE_ID}.p2.fq.gz"

PANVC2_FOUNDER_COUNT			= 2
PANVC2_BWA_THREADS				= 40

WORKFLOWS = [
	"bowtie2",
	"vg-map",
	"vg-giraffe",
	"reference-flow",
	"panvc2",
	"panvc3-bowtie2-f2-d2.mapq-recalculated",
	"panvc3-bowtie2-f2-d2.max-mapq",
	"panvc3-bowtie2-f7-d10.mapq-recalculated",
	"panvc3-bowtie2-f7-d10.max-mapq",
	"panvc3-bowtie2-f10-d15.mapq-recalculated",
	"panvc3-bowtie2-f10-d15.max-mapq",
	"panvc3-bowtie2-f14-d25.mapq-recalculated",
	"panvc3-bowtie2-f14-d25.max-mapq",
	"panvc3-bowtie2-f25-d50.mapq-recalculated",
	"panvc3-bowtie2-f25-d50.max-mapq"
]


sys.path.append(f"{workflow.basedir}/../lib/panvc2/pvc_py_tools")


# Copied from the take-one-out experiment.
def reference_contigs():
	with open(f"{REFERENCE_FA}.gz.fai", "r") as fp:
		for line in fp:
			line = line.rstrip("\n")
			fields = line.split("\t")
			yield fields[0]

def non_founder_sequence_contigs():
	founder_sequence_contigs = frozenset(CHROMOSOMES)
	return filter(lambda x: x not in founder_sequence_contigs, reference_contigs())


BOWTIE2_CONFIG = {
	"alignment_id":								SAMPLE_ID,
	"reference":								REFERENCE_FA,
	"reads_1":									READS_1,
	"reads_2":									READS_2
}

PANVC3_CONFIG = {
	"alignment_id":								SAMPLE_ID,
	"reference":								REFERENCE_FA,
	"chromosomes":								CHROMOSOMES,
	"known_variants_prefix":					"input/known-variants.",
	"known_variants_suffix":					".vcf",
	"reads_1":									READS_1,
	"reads_2":									READS_2,
	"panvc3_conda_environment_path":			"../environments/panvc3.yaml",
	"vcf2multialign_conda_environment_path":	"../environments/vcf2multialign.yaml"
}

PANVC2_INDEX_CONFIG = {
	"benchmark_dir":							"benchmark/panvc2/index",
	"index_root":								"index/panvc2",
	"input_a2m":								[(x, f"panvc2/a2m/{x}.a2m") for x in reference_contigs()],
	"max_edit_distance":						10,
	"max_memory_MB":							1024 * MEM_GB,
	"max_read_length":							105,
	"n_refs":									1 + PANVC2_FOUNDER_COUNT,
	"tempdir":									"temp/panvc2/index"
}

PANVC2_CONFIG = {
	"benchmark_dir":							"benchmark/panvc2/index",
	"index_root":								"index/panvc2",
	"chromosome_list":							list(reference_contigs()),
	"max_edit_distance":						10,
	"max_memory_MB":							1024 * MEM_GB,
	"max_read_len":								105,
	"n_refs":									1 + PANVC2_FOUNDER_COUNT,
	"output_root":								f"panvc2/call/{SAMPLE_ID}",
	"ploidy":									2,
	"ploidy_file":								"GRCh37",
	"reads_file_1":								READS_1,
	"reads_file_2":								READS_2,
	"reads_all_path":							"panvc2/reads/all.fastq.gz",
	"sensibility":								5,
	"tempdir":									"temp/panvc2/call",
	"variant_caller":							["gatk"],
	"workflow":									["pg"],
	"call_regions":								CHROMOSOMES,
	"bwa_threads":								PANVC2_BWA_THREADS,
	"panvc2_subdir":							"../lib/panvc2"
}

VG_CONFIG = {
	"alignment_id":								SAMPLE_ID,
	"reference":								REFERENCE_FA,
	"known_variants":							"input/known-variants.1.vcf.gz",
	"reads_1":									READS_1,
	"reads_2":									READS_2,
	"mem_gb":									MEM_GB
}


def none_if_empty(x):
	return x if bool(x) else None


wildcard_constraints:
	sample_id	= r"[^.]+",
	chromosome_	= "|".join(map(lambda x: f"({re.escape(x)})", CHROMOSOMES))


rule all:
	input:
		reference_bias			= "reference-bias-summary.tsv.gz",
		precision_and_recall	= "alignment-precision-recall-summary.tsv"


rule alignments:
	input:	expand("alignments/{sample_id}.{wf}.bam", sample_id = SAMPLE_ID, wf = WORKFLOWS)


rule alignment_precision_recall:
	input:	expand("alignments/{sample_id}.{wf}.qname-sorted.bam", sample_id = SAMPLE_ID, wf = WORKFLOWS)


rule supporting_read_counts:
	input:	expand("supporting-reads-counts/{sample_id}.{wf}.{chromosome}.{regions}.txt.gz", sample_id = SAMPLE_ID, wf = WORKFLOWS, chromosome = CHROMOSOMES, regions = ["all", "confident"])


rule alignment_precision_recall_summary:
	conda:	"../workflow/environments/biopython.yaml"
	input:	expand("alignment-precision-recall/{sample_id}.{wf}.d{dist}.tsv", sample_id = SAMPLE_ID, wf = WORKFLOWS, dist = [0, 5, 10, 20, 30])
	output:	"alignment-precision-recall-summary.tsv"
	shell:	"python3 scripts/summarise_alignment_precision_recall.py > {output}"


rule reference_bias_summary:
	conda:		"../workflow/environments/biopython.yaml"
	threads:	2
	input:		expand("reference-bias/{sample_id}.{wf}.{chromosome}.{regions}.mc{mc}.txt.gz", sample_id = SAMPLE_ID, wf = WORKFLOWS, chromosome = CHROMOSOMES, regions = ["all", "confident"], mc = [1, 5, 10, 15, 20, 25]),
	output:		"reference-bias-summary.tsv.gz"
	shell:		"python3 scripts/summarise_reference_bias.py | gzip > {output}"


module common_rules:
	snakefile:	"../workflow/rules/common.smk"

use rule * from common_rules as common_*


module bowtie2_workflow:
	snakefile:	"../workflow/rules/bowtie2.smk"
	config:		BOWTIE2_CONFIG

use rule * from bowtie2_workflow as bowtie2_*


module panvc3_workflow:
	snakefile:	"../workflow/rules/panvc3.smk"
	config:		PANVC3_CONFIG

use rule * from panvc3_workflow as panvc3_*


module panvc2_indexing_workflow:
	snakefile:	"../lib/panvc2/Snakefile.index"
	config:		PANVC2_INDEX_CONFIG

use rule * from panvc2_indexing_workflow as panvc2_index_*


module panvc2_workflow:
	snakefile:	"../lib/panvc2/Snakefile.call"
	config:		PANVC2_CONFIG

use rule * from panvc2_workflow as panvc2_call_*


module vg_workflow:
	snakefile:	"../workflow/rules/vg.smk"
	config:		VG_CONFIG

use rule * from vg_workflow as vg_*


# Enable when this is resolved: https://github.com/snakemake/snakemake/issues/2499
#configfile: "config/reference-flow.yaml"
#
#module reference_flow_workflow:
#	snakefile:	"lib/reference_flow/snakemake/Snakefile"
#	config: config["reference_flow"]
#
#use rule * from reference_flow_workflow as reference_flow_*
#
#use rule all from reference_flow_workflow as reference_flow_all with:
#	benchmark:	"benchmark/reference_flow"

rule reference_flow_run:
	threads:		workflow.cores
	benchmark:		"benchmark/run_reference_flow_sp/{sample_id}"
	input:
		reads_1		= READS_1,
		reads_2		= READS_2
	output:			"alignments/{sample_id}.reference-flow.sam"
	params:
		rf_output	= "reference-flow/run/experiments/{sample_id}/thrds0_S1_b1000_ld1/chr1-refflow-10-thrds0_S1_b1000_ld1-liftover.sam"
	shell:			"snakemake --printshellcmds --cores {threads} --snakefile ../lib/reference_flow/snakemake/Snakefile --use-conda --conda-prefix ../conda-env --configfile config/reference-flow-sp.yaml -- && mkdir -p alignments && mv {params.rf_output} {output}"


rule remove_sample_from_known_variants:
	message:			"Removing the tested sample from known variants"
	conda:				"../workflow/environments/bcftools.yaml"
	input:				expand(f"{KNOWN_VARIANTS_PREFIX}{{chromosome}}{KNOWN_VARIANTS_SUFFIX}", chromosome = CHROMOSOMES)
	output:				"input/known-variants.{chromosome}.vcf"
	params:
		removed_samples	= lambda _: ",".join(map(lambda x: f"^{x}", KNOWN_VARIANTS_REMOVED_SAMPLES))
	shell:				"bcftools view -s {params.removed_samples} -O v -o {output} {input}"


rule filter_heterozygous_variants_from_truth:
	message:		"Filtering heterozygous variants from the truth"
	conda:			"../workflow/environments/vcf2multialign.yaml"
	priority:		100
	input:	
		truth		= TRUTH
	output:			"input/tested-variants.{chromosome}.vcf"
	shell:			"vcfcat"
					" --input={input.truth}"
					" --output={output}"
					" --chromosome={wildcards.chromosome}"
					" --zygosity=1"
					" --replace-missing-id=unknown-"
					" --genotype-field=GT"
					" --omit-info"
					" --skip-invalid"


rule generate_predicted_sequences:
	message:		"Generating predicted haplotype sequences"
	conda:			"../workflow/environments/vcf2multialign.yaml"
	priority:		100
	input:
		reference	= REFERENCE_FA,
		variants	= "input/tested-variants.{chromosome}.vcf"
	output:
		haplotype_1	= "input/{chromosome}.{sample_id}.1.fa",
		haplotype_2	= "input/{chromosome}.{sample_id}.2.fa",
		overlaps	= "input/overlaps.{chromosome}.{sample_id}.tsv"
	shell:			"cd input && vcf2multialign"
					" --haplotypes"
					" --input-reference=../{input.reference}"
					" --reference-sequence={wildcards.chromosome}"
					" --input-variants=../{input.variants}"
					" --chromosome={wildcards.chromosome}"
					" --dst-chromosome={wildcards.chromosome}"
					" --output-sequences-separate"
					" --separate-output-format=A2M"
					" --output-overlaps=overlaps.{wildcards.chromosome}.tsv"
					" --omit-reference"
					" --unaligned"


rule generate_predicated_a2m:
	message:		"Generating MSA of the predicted sequences"
	conda:			"../workflow/environments/vcf2multialign.yaml"
	input:
		reference	= REFERENCE_FA,
		variants	= "input/tested-variants.{chromosome}.vcf"
	output:
		msa			= "msa-index/truth.{chromosome}.a2m.gz",
		overlaps	= "msa-index/overlaps.{chromosome}.tsv"
	shell:			"vcf2multialign"
					" --haplotypes"
					" --input-reference={input.reference}"
					" --reference-sequence={wildcards.chromosome}"
					" --input-variants={input.variants}"
					" --chromosome={wildcards.chromosome}"
					" --dst-chromosome={wildcards.chromosome}"
					" --output-sequences-a2m={output.msa}"
					" --output-overlaps={output.overlaps}"
					" --pipe=../workflow/scripts/run-gzip.sh"


rule combine_predicted_a2m:
	message:		"Combining the MSAs of the predicted sequences"
	input:			expand("msa-index/truth.{chromosome}.a2m.gz", chromosome = CHROMOSOMES)
	output:			"msa-index/truth.a2m.gz"
	shell:			"cat {input} > {output}"


rule index_msa:
	# FIXME: conda
	message:		"Building the MSA index"
	input:			"msa-index/truth.a2m.gz"
	output:			"msa-index/truth.dat"
	shell:			"panvc3_index_msa"
					" --build-index"
					" --sequences={input}"
					" --msa-index-output={output}"
					" --pipe-input='gzip -d -c'"


rule generate_reads:
	message:		"Generating reads"
	conda:			"../workflow/environments/mason.yaml"
	threads:		workflow.cores
	input:
		reference	= "input/{chromosome}.{sample_id}.{chr_copy}.fa"
	output:
		temp_dir	= temp(directory("temp/mason/temp.{sample_id}.{chromosome}.s{chr_copy}")),
		alignments	= "reads/{sample_id}.{chromosome}.s{chr_copy}.bam",
		reads_1		= "reads/{sample_id}.{chromosome}.s{chr_copy}.p1.fq.gz",
		reads_2		= "reads/{sample_id}.{chromosome}.s{chr_copy}.p2.fq.gz"
	params:
		chr_idx		= lambda wildcards: ALL_CHROMOSOMES.index(wildcards.chromosome)
	shell:			"mkdir -p {output.temp_dir} && TMPDIR={output.temp_dir} mason_simulator"
					" --verbose"
					" --seed $((21 + {wildcards.chr_copy} + {params.chr_idx}))"
					" --read-name-prefix simulated.s{wildcards.chr_copy}."
					" --num-threads {threads}"
					" --num-fragments 30000000"
					" --out {output.reads_1}"
					" --out-right {output.reads_2}"
					" --out-alignment {output.alignments}"
					" --input-reference {input.reference}"
					" --seq-technology illumina"
					" --illumina-read-length 101"


rule concatenate_reads:
	message:		"Concatenating reads"
	input:			expand("reads/{{sample_id}}.{chromosome}.s{chr_copy}.p{{pair}}.fq.gz", chromosome = CHROMOSOMES, chr_copy = [1, 2])
	output:			"reads/{sample_id}.p{pair}.fq.gz"
	shell:			"cat {input} > {output}"


# samtools cat requires identical headers while merge rewrites the records, so we use the latter.
rule merge_aligned:
	message:		"Merging generated alignments"
	conda:			"../workflow/environments/samtools.yaml"
	threads:		8
	input:			expand("reads/{{sample_id}}.{chromosome}.s{chr_copy}.sorted.bam", chromosome = CHROMOSOMES, chr_copy = [1, 2])
	output:			"reads/{sample_id}.sorted.bam"
	shell:			"samtools merge -@ {threads} -O BAM -o {output} {input}"


rule reheader_aligned:
	message:		"Rewriting the header of the generated alignments"
	conda:			"../workflow/environments/biopython.yaml"
	input:			
		alignments	= "reads/{sample_id}.sorted.bam",
		rnames		= "reference-mapping/truth.tsv"
	output:			"reads/{sample_id}.rh.sorted.bam"
	shell:			"samtools reheader -c 'python3 ../workflow/scripts/replace_sam_rname_header.py {input.rnames}' {input.alignments} > {output}"


rule project_truth_alignments:
	# FIXME: conda
	threads:			8
	input:			
		alignments		= "reads/{sample_id}.rh.sorted.bam",
		msa_index		= "msa-index/truth.dat",
		reference		= f"{REFERENCE_FA}.gz",
		reference_fai	= f"{REFERENCE_FA}.gz.fai",
		reference_gzi	= f"{REFERENCE_FA}.gz.gzi"
	output:				"reads/{sample_id}.projected.sam.gz"
	shell:				"panvc3_project_alignments"
						" --alignments={input.alignments}"
						" --msa-index={input.msa_index}"
						" --reference={input.reference}"
						" --reference-msa-id=REF"
						" --ref-id-separator=/"
						" | gzip > {output}"


# prepare_panvc2_input_founders and prepare_panvc2_input_rest copied from the take-one-out experiment. Consider adding a module.
rule prepare_panvc2_input_founders:
	input:				"panvc3/founder-sequences/chromosome.{chromosome_}.f2.d2.a2m.gz"
	output:				"panvc2/a2m/{chromosome_}.a2m"
	shell:				"gunzip -c -k {input} | sed -E 's/^[>][^\t]+\t(.*)$/>\1/' > {output}"


rule prepare_panvc2_input_rest:
	conda:				"../workflow/environments/biopython.yaml"
	params:
		founder_count	= PANVC2_FOUNDER_COUNT,
	input:				"panvc3/founder-sequences/remaining-contigs.fa.gz"
	output:				expand("panvc2/a2m/{chromosome}.a2m", chromosome = non_founder_sequence_contigs())
	shell:				"gunzip -c -k {input} | python3 ../workflow/scripts/prepare_panvc2_input_rest.py {params.founder_count} panvc2/a2m/"


rule index_second_stage_panvc2:
	conda:				"../workflow/environments/bowtie2.yaml"
	threads:			workflow.cores
	input:				"panvc2/call/{sample_id}/ext_vc/reference.fa"
	output:				multiext("panvc2/call/{sample_id}/bowtie2/index", ".1.bt2", ".2.bt2", ".3.bt2", ".4.bt2", ".rev.1.bt2", ".rev.2.bt2")
	shell:				"bowtie2-build --threads {threads} {input} panvc2/call/{sample_id}/bowtie2/index"


rule align_second_stage_panvc2:
	conda:				"../workflow/environments/bowtie2.yaml"
	threads:			workflow.cores
	input:
		index			= multiext("panvc2/call/{sample_id}/bowtie2/index", ".1.bt2", ".2.bt2", ".3.bt2", ".4.bt2", ".rev.1.bt2", ".rev.2.bt2"),
		reads_1			= READS_1,
		reads_2			= READS_2
	output:				"panvc2/call/{sample_id}/bowtie2/alignments.sam.gz"
	shell:				"bowtie2 --threads {threads} -1 {input.reads_1} -2 {input.reads_2} -x panvc2/call/{sample_id}/bowtie2/index | gzip > {output}"


rule reheader_aligned_panvc2:
	conda:			"../workflow/environments/biopython.yaml"
	input:			
		alignments	= "panvc2/call/{sample_id}/bowtie2/alignments.bam",
		rnames		= "reference-mapping/panvc2.tsv"
	output:			"panvc2/call/{sample_id}/bowtie2/alignments.rh.bam"
	shell:			"samtools reheader -c 'python3 ../workflow/scripts/replace_sam_rname_header.py {input.rnames}' {input.alignments} > {output}"


rule prepare_msa_index_input_panvc2:
	input:
		source		= "panvc2/call/{sample_id}/adhoc_ref_files/{chromosome}/adhoc_reference.aligned_to_ref",
		target		= "index/panvc2/{chromosome}/recombinant.n1.gapped"
	output:			"panvc2/call/{sample_id}/truth/{chromosome}.a2m.gz"
	params:
		source		= lambda ww: f"panvc2/call/{ww.sample_id}/adhoc_ref_files/{ww.chromosome}/adhoc_reference.aligned_to_ref",
		target		= lambda ww: f"index/panvc2/{ww.chromosome}/recombinant.n1.gapped"
	shell:			"(printf '>%s\tREF\\n' '{wildcards.chromosome}' && cat {input.target} && printf '>%s\t1\\n' '{wildcards.chromosome}' && cat {input.source}) | gzip > {output}"


rule combine_msa_index_input_panvc2:
	input:			
		tested		= expand("panvc2/call/{{sample_id}}/truth/{chromosome}.a2m.gz", chromosome = CHROMOSOMES),
		rest		= "panvc3/founder-sequences/remaining-contigs.fa.gz"
	output:			"panvc2/call/{sample_id}/truth.a2m.gz"
	shell:			"cat {input.tested} {input.rest} > {output}"


rule index_msa_panvc2:
	# FIXME: conda
	message:		"Building the MSA index"
	input:			"panvc2/call/{sample_id}/truth.a2m.gz"
	output:			"panvc2/call/{sample_id}/truth.dat"
	shell:			"panvc3_index_msa"
					" --build-index"
					" --sequences={input}"
					" --msa-index-output={output}"
					" --pipe-input='gzip -d -c'"


rule project_alignments_panvc2:
	# FIXME: conda
	threads:			8
	input:			
		alignments		= "panvc2/call/{sample_id}/bowtie2/alignments.rh.sorted.bam",
		msa_index		= "panvc2/call/{sample_id}/truth.dat",
		reference		= f"{REFERENCE_FA}.gz",
		reference_fai	= f"{REFERENCE_FA}.gz.fai",
		reference_gzi	= f"{REFERENCE_FA}.gz.gzi"
	output:				"alignments/{sample_id}.panvc2.sam.gz"
	shell:				"panvc3_project_alignments"
						" --alignments={input.alignments}"
						" --msa-index={input.msa_index}"
						" --reference={input.reference}"
						" --reference-msa-id=REF"
						" --ref-id-separator=/"
						" | gzip > {output}"


rule count_supporting_reads:
	message:			"Counting supporting reads"
	conda:				"../workflow/environments/panvc3.yaml"
	threads:			4
	input:				
		alignments		= "alignments/{sample_id}.{wf}.sorted.bam",
		variants		= "input/tested-variants.{chromosome}.vcf"
	output:				"supporting-reads-counts/{sample_id}.{wf}.{chromosome}.{regions}.txt.gz"
	params:
		regions_param	= lambda wildcards: f"--regions={CONFIDENT_REGIONS}" if "confident" == wildcards.regions else ""
	shell:				"set +o pipefail && samtools view -@ 2 {input.alignments} | panvc3_count_supporting_reads --vcf={input.variants} --chr={wildcards.chromosome} --contig={wildcards.chromosome} {params.regions_param} | gzip -c --verbose > {output}"


rule calculate_reference_bias:
	message:			"Calculating reference bias"
	conda:				"../workflow/environments/panvc3.yaml"
	threads:			3
	input:				"supporting-reads-counts/{sample_id}.{wf}.{chromosome}.{regions}.txt.gz"
	output:				"reference-bias/{sample_id}.{wf}.{chromosome}.{regions}.mc{mc}.txt.gz"
	shell:				"gunzip -c -k {input} | panvc3_calculate_reference_bias.py --min-coverage {wildcards.mc} | gzip > {output}"


rule calculate_precision_recall:
	message:			"Calculating alignment precision and recall"
	conda:				"../workflow/environments/biopython.yaml"
	input:
		truth			= "reads/{sample_id}.projected.qname-sorted.bam",
		tested			= "alignments/{sample_id}.{wf}.qname-sorted.bam"
	output:				"alignment-precision-recall/{sample_id}.{wf}.d{dist}.tsv"
	shell:				"python3"
						" ../workflow/scripts/alignment_position_precision_recall.py"
						" --distance-threshold {wildcards.dist}"
						" {input.truth}"
						" {input.tested}"
						" > {output}"
